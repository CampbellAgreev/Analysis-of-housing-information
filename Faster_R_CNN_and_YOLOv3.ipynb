{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMQBpaZSoLr+11C90uc7KXY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CampbellAgreev/Analysis-of-housing-information/blob/master/Faster_R_CNN_and_YOLOv3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKaUSbr8Lyyj",
        "outputId": "cebb1b02-bdeb-4dbe-ced2-d52eba942f67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "fatal: destination path 'ObjectDetection' already exists and is not an empty directory.\n",
            "/content/drive/MyDrive/Project Folder/ObjectDetection\n",
            "mv: cannot stat '../simpsons_dataset': No such file or directory\n",
            "mv: cannot stat '../annotation.txt': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "import os\n",
        "project_dir = \"/content/drive/MyDrive/Project Folder\"\n",
        "os.chdir(project_dir)\n",
        "!git clone https://github.com/duckrabbits/ObjectDetection.git\n",
        "%cd ObjectDetection\n",
        "!mv ../simpsons_dataset ./simpsons_dataset\n",
        "!mv ../annotation.txt ./annotation.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow keras opencv-python-headless scikit-image h5py matplotlib\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-HGwonzMcbw",
        "outputId": "938a6e29-b7ae-4d6e-8538-6666164434f6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.8.0)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (3.13.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.15.0)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (1.15.3)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (3.4.2)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (11.2.1)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2025.5.10)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (0.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!python train.py -p annotation.txt -E 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7lEXiVyNAFL",
        "outputId": "42cd2f23-a231-423a-fdd2-d8057cf2eec5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-05-25 23:26:10.078371: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1748215570.145446    1237 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1748215570.165644    1237 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-25 23:26:10.254331: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Using dataset from: /content/drive/MyDrive/Project Folder/ObjectDetection/simpsons_dataset\n",
            "Training set: (14317, 64, 64, 3), (14317, 18)\n",
            "Test set: (2527, 64, 64, 3), (2527, 18)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "2025-05-25 23:33:43.999543: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1748216024.001249    1237 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "Starting training...\n",
            "2025-05-25 23:33:45.815896: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 703709184 exceeds 10% of free system memory.\n",
            "2025-05-25 23:33:46.435792: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 703709184 exceeds 10% of free system memory.\n",
            "Epoch 1/200\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1748216028.277755   23252 service.cc:148] XLA service 0x79ca680042b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1748216028.277864   23252 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2025-05-25 23:33:48.345008: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "I0000 00:00:1748216028.536498   23252 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
            "2025-05-25 23:33:49.576370: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[32,32,64,64]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,3,64,64]{3,2,1,0}, f32[32,3,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
            "2025-05-25 23:33:49.794043: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[32,32,62,62]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,64,64]{3,2,1,0}, f32[32,32,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
            "2025-05-25 23:33:49.890457: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[32,64,31,31]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,31,31]{3,2,1,0}, f32[64,32,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
            "2025-05-25 23:33:49.976480: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[32,64,29,29]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,31,31]{3,2,1,0}, f32[64,64,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
            "2025-05-25 23:33:50.046261: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[32,256,14,14]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,14,14]{3,2,1,0}, f32[256,64,3,3]{3,2,1,0}, f32[256]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
            "2025-05-25 23:33:50.110582: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[32,256,12,12]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,256,14,14]{3,2,1,0}, f32[256,256,3,3]{3,2,1,0}, f32[256]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
            "I0000 00:00:1748216034.945329   23252 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "\u001b[1m447/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1078 - loss: 2.76732025-05-25 23:34:02.298033: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[13,32,64,64]{3,2,1,0}, u8[0]{0}) custom-call(f32[13,3,64,64]{3,2,1,0}, f32[32,3,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
            "2025-05-25 23:34:02.331410: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[13,32,62,62]{3,2,1,0}, u8[0]{0}) custom-call(f32[13,32,64,64]{3,2,1,0}, f32[32,32,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
            "2025-05-25 23:34:02.374299: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[13,64,31,31]{3,2,1,0}, u8[0]{0}) custom-call(f32[13,32,31,31]{3,2,1,0}, f32[64,32,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
            "2025-05-25 23:34:02.410524: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[13,64,29,29]{3,2,1,0}, u8[0]{0}) custom-call(f32[13,64,31,31]{3,2,1,0}, f32[64,64,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
            "2025-05-25 23:34:02.459258: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[13,256,14,14]{3,2,1,0}, u8[0]{0}) custom-call(f32[13,64,14,14]{3,2,1,0}, f32[256,64,3,3]{3,2,1,0}, f32[256]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
            "2025-05-25 23:34:02.502715: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[13,256,12,12]{3,2,1,0}, u8[0]{0}) custom-call(f32[13,256,14,14]{3,2,1,0}, f32[256,256,3,3]{3,2,1,0}, f32[256]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1080 - loss: 2.76692025-05-25 23:34:06.583419: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[32,32,64,64]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,3,64,64]{3,2,1,0}, f32[32,3,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
            "2025-05-25 23:34:06.667837: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[32,32,62,62]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,64,64]{3,2,1,0}, f32[32,32,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
            "2025-05-25 23:34:06.737148: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[32,64,31,31]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,31,31]{3,2,1,0}, f32[64,32,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
            "2025-05-25 23:34:06.820405: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[32,64,29,29]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,31,31]{3,2,1,0}, f32[64,64,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
            "2025-05-25 23:34:06.890712: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[32,256,14,14]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,14,14]{3,2,1,0}, f32[256,64,3,3]{3,2,1,0}, f32[256]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
            "2025-05-25 23:34:06.938464: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[32,256,12,12]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,256,14,14]{3,2,1,0}, f32[256,256,3,3]{3,2,1,0}, f32[256]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
            "2025-05-25 23:34:07.830168: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[31,32,64,64]{3,2,1,0}, u8[0]{0}) custom-call(f32[31,3,64,64]{3,2,1,0}, f32[32,3,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
            "2025-05-25 23:34:07.878018: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[31,32,62,62]{3,2,1,0}, u8[0]{0}) custom-call(f32[31,32,64,64]{3,2,1,0}, f32[32,32,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
            "2025-05-25 23:34:07.933294: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[31,64,31,31]{3,2,1,0}, u8[0]{0}) custom-call(f32[31,32,31,31]{3,2,1,0}, f32[64,32,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
            "2025-05-25 23:34:07.983858: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[31,64,29,29]{3,2,1,0}, u8[0]{0}) custom-call(f32[31,64,31,31]{3,2,1,0}, f32[64,64,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
            "2025-05-25 23:34:08.038549: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[31,256,14,14]{3,2,1,0}, u8[0]{0}) custom-call(f32[31,64,14,14]{3,2,1,0}, f32[256,64,3,3]{3,2,1,0}, f32[256]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
            "2025-05-25 23:34:08.085598: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[31,256,12,12]{3,2,1,0}, u8[0]{0}) custom-call(f32[31,256,14,14]{3,2,1,0}, f32[256,256,3,3]{3,2,1,0}, f32[256]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 31ms/step - accuracy: 0.1082 - loss: 2.7664 - val_accuracy: 0.3126 - val_loss: 2.2432\n",
            "Epoch 2/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.4293 - loss: 1.9037 - val_accuracy: 0.5900 - val_loss: 1.3893\n",
            "Epoch 3/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.6140 - loss: 1.2836 - val_accuracy: 0.7024 - val_loss: 1.0433\n",
            "Epoch 4/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.7148 - loss: 0.9416 - val_accuracy: 0.7432 - val_loss: 0.8849\n",
            "Epoch 5/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.7769 - loss: 0.7200 - val_accuracy: 0.7990 - val_loss: 0.6680\n",
            "Epoch 6/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - accuracy: 0.8331 - loss: 0.5417 - val_accuracy: 0.7974 - val_loss: 0.6960\n",
            "Epoch 7/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.8705 - loss: 0.4359 - val_accuracy: 0.8338 - val_loss: 0.5999\n",
            "Epoch 8/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.8871 - loss: 0.3552 - val_accuracy: 0.8370 - val_loss: 0.5971\n",
            "Epoch 9/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9041 - loss: 0.3029 - val_accuracy: 0.8571 - val_loss: 0.5503\n",
            "Epoch 10/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9146 - loss: 0.2729 - val_accuracy: 0.8631 - val_loss: 0.5396\n",
            "Epoch 11/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9349 - loss: 0.2062 - val_accuracy: 0.8690 - val_loss: 0.4870\n",
            "Epoch 12/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9439 - loss: 0.1871 - val_accuracy: 0.8722 - val_loss: 0.5037\n",
            "Epoch 13/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9453 - loss: 0.1743 - val_accuracy: 0.8753 - val_loss: 0.5360\n",
            "Epoch 14/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9530 - loss: 0.1432 - val_accuracy: 0.8571 - val_loss: 0.5599\n",
            "Epoch 15/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9559 - loss: 0.1463 - val_accuracy: 0.8757 - val_loss: 0.5984\n",
            "Epoch 16/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9610 - loss: 0.1330 - val_accuracy: 0.8916 - val_loss: 0.4813\n",
            "Epoch 17/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - accuracy: 0.9647 - loss: 0.1175 - val_accuracy: 0.8750 - val_loss: 0.5658\n",
            "Epoch 18/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9624 - loss: 0.1207 - val_accuracy: 0.8785 - val_loss: 0.5695\n",
            "Epoch 19/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9646 - loss: 0.1170 - val_accuracy: 0.8821 - val_loss: 0.5890\n",
            "Epoch 20/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9683 - loss: 0.1079 - val_accuracy: 0.8848 - val_loss: 0.5938\n",
            "Epoch 21/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.9656 - loss: 0.1138 - val_accuracy: 0.8825 - val_loss: 0.6296\n",
            "Epoch 22/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9621 - loss: 0.1261 - val_accuracy: 0.8856 - val_loss: 0.5204\n",
            "Epoch 23/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9703 - loss: 0.0949 - val_accuracy: 0.8718 - val_loss: 0.6820\n",
            "Epoch 24/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9691 - loss: 0.0997 - val_accuracy: 0.8848 - val_loss: 0.6276\n",
            "Epoch 25/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9742 - loss: 0.0936 - val_accuracy: 0.8864 - val_loss: 0.5377\n",
            "Epoch 26/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - accuracy: 0.9796 - loss: 0.0661 - val_accuracy: 0.8943 - val_loss: 0.5675\n",
            "Epoch 27/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9694 - loss: 0.1057 - val_accuracy: 0.8880 - val_loss: 0.5575\n",
            "Epoch 28/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9779 - loss: 0.0826 - val_accuracy: 0.8841 - val_loss: 0.6318\n",
            "Epoch 29/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9777 - loss: 0.0677 - val_accuracy: 0.8876 - val_loss: 0.5914\n",
            "Epoch 30/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9783 - loss: 0.0747 - val_accuracy: 0.8658 - val_loss: 0.7047\n",
            "Epoch 31/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9798 - loss: 0.0713 - val_accuracy: 0.8785 - val_loss: 0.6159\n",
            "Epoch 32/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9779 - loss: 0.0791 - val_accuracy: 0.8876 - val_loss: 0.5583\n",
            "Epoch 33/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9833 - loss: 0.0611 - val_accuracy: 0.8963 - val_loss: 0.5006\n",
            "Epoch 34/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9826 - loss: 0.0515 - val_accuracy: 0.8852 - val_loss: 0.5881\n",
            "Epoch 35/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9801 - loss: 0.0633 - val_accuracy: 0.9007 - val_loss: 0.5085\n",
            "Epoch 36/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.9809 - loss: 0.0677 - val_accuracy: 0.8829 - val_loss: 0.6374\n",
            "Epoch 37/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9849 - loss: 0.0558 - val_accuracy: 0.8904 - val_loss: 0.5840\n",
            "Epoch 38/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9808 - loss: 0.0647 - val_accuracy: 0.8904 - val_loss: 0.6184\n",
            "Epoch 39/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9841 - loss: 0.0568 - val_accuracy: 0.8916 - val_loss: 0.5034\n",
            "Epoch 40/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9793 - loss: 0.0758 - val_accuracy: 0.8932 - val_loss: 0.5824\n",
            "Epoch 41/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9845 - loss: 0.0515 - val_accuracy: 0.8852 - val_loss: 0.6747\n",
            "Epoch 42/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.9850 - loss: 0.0551 - val_accuracy: 0.8975 - val_loss: 0.5885\n",
            "Epoch 43/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9885 - loss: 0.0442 - val_accuracy: 0.8959 - val_loss: 0.6214\n",
            "Epoch 44/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9899 - loss: 0.0363 - val_accuracy: 0.8876 - val_loss: 0.6527\n",
            "Epoch 45/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 18ms/step - accuracy: 0.9852 - loss: 0.0482 - val_accuracy: 0.9015 - val_loss: 0.5806\n",
            "Epoch 46/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9885 - loss: 0.0403 - val_accuracy: 0.8686 - val_loss: 0.7577\n",
            "Epoch 47/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9838 - loss: 0.0523 - val_accuracy: 0.8928 - val_loss: 0.6763\n",
            "Epoch 48/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9917 - loss: 0.0276 - val_accuracy: 0.8841 - val_loss: 0.6853\n",
            "Epoch 49/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9869 - loss: 0.0461 - val_accuracy: 0.8876 - val_loss: 0.6376\n",
            "Epoch 50/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9846 - loss: 0.0598 - val_accuracy: 0.8943 - val_loss: 0.6267\n",
            "Epoch 51/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9810 - loss: 0.0627 - val_accuracy: 0.8939 - val_loss: 0.5955\n",
            "Epoch 52/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9893 - loss: 0.0408 - val_accuracy: 0.8951 - val_loss: 0.5856\n",
            "Epoch 53/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9883 - loss: 0.0469 - val_accuracy: 0.9082 - val_loss: 0.6241\n",
            "Epoch 54/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9895 - loss: 0.0350 - val_accuracy: 0.8872 - val_loss: 0.5852\n",
            "Epoch 55/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.9864 - loss: 0.0481 - val_accuracy: 0.8999 - val_loss: 0.5315\n",
            "Epoch 56/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9869 - loss: 0.0431 - val_accuracy: 0.8979 - val_loss: 0.5915\n",
            "Epoch 57/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9858 - loss: 0.0478 - val_accuracy: 0.8971 - val_loss: 0.4902\n",
            "Epoch 58/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9885 - loss: 0.0393 - val_accuracy: 0.8999 - val_loss: 0.5866\n",
            "Epoch 59/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9895 - loss: 0.0356 - val_accuracy: 0.9042 - val_loss: 0.5512\n",
            "Epoch 60/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.9887 - loss: 0.0404 - val_accuracy: 0.8900 - val_loss: 0.6311\n",
            "Epoch 61/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9884 - loss: 0.0405 - val_accuracy: 0.8805 - val_loss: 0.7003\n",
            "Epoch 62/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - accuracy: 0.9809 - loss: 0.0764 - val_accuracy: 0.8955 - val_loss: 0.5748\n",
            "Epoch 63/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9883 - loss: 0.0389 - val_accuracy: 0.8904 - val_loss: 0.5755\n",
            "Epoch 64/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9917 - loss: 0.0302 - val_accuracy: 0.8999 - val_loss: 0.6704\n",
            "Epoch 65/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9820 - loss: 0.0643 - val_accuracy: 0.8916 - val_loss: 0.6059\n",
            "Epoch 66/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9873 - loss: 0.0468 - val_accuracy: 0.9023 - val_loss: 0.6133\n",
            "Epoch 67/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - accuracy: 0.9896 - loss: 0.0371 - val_accuracy: 0.8765 - val_loss: 0.6817\n",
            "Epoch 68/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9858 - loss: 0.0524 - val_accuracy: 0.9019 - val_loss: 0.5683\n",
            "Epoch 69/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9869 - loss: 0.0439 - val_accuracy: 0.8841 - val_loss: 0.6853\n",
            "Epoch 70/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - accuracy: 0.9850 - loss: 0.0582 - val_accuracy: 0.8912 - val_loss: 0.6318\n",
            "Epoch 71/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9900 - loss: 0.0380 - val_accuracy: 0.8872 - val_loss: 0.6610\n",
            "Epoch 72/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9876 - loss: 0.0435 - val_accuracy: 0.8963 - val_loss: 0.6397\n",
            "Epoch 73/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.9863 - loss: 0.0503 - val_accuracy: 0.8951 - val_loss: 0.8347\n",
            "Epoch 74/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9890 - loss: 0.0446 - val_accuracy: 0.9038 - val_loss: 0.6500\n",
            "Epoch 75/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9864 - loss: 0.0519 - val_accuracy: 0.8789 - val_loss: 0.8023\n",
            "Epoch 76/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9808 - loss: 0.0733 - val_accuracy: 0.8995 - val_loss: 0.5668\n",
            "Epoch 77/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9843 - loss: 0.0540 - val_accuracy: 0.8967 - val_loss: 0.6936\n",
            "Epoch 78/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9830 - loss: 0.0661 - val_accuracy: 0.9023 - val_loss: 0.5493\n",
            "Epoch 79/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9842 - loss: 0.0575 - val_accuracy: 0.8987 - val_loss: 0.6657\n",
            "Epoch 80/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9840 - loss: 0.0640 - val_accuracy: 0.8995 - val_loss: 0.6185\n",
            "Epoch 81/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9892 - loss: 0.0354 - val_accuracy: 0.9007 - val_loss: 0.5988\n",
            "Epoch 82/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9905 - loss: 0.0339 - val_accuracy: 0.8983 - val_loss: 0.7057\n",
            "Epoch 83/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9847 - loss: 0.0582 - val_accuracy: 0.8781 - val_loss: 0.7976\n",
            "Epoch 84/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9843 - loss: 0.0636 - val_accuracy: 0.8951 - val_loss: 0.6679\n",
            "Epoch 85/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9867 - loss: 0.0512 - val_accuracy: 0.9023 - val_loss: 0.6212\n",
            "Epoch 86/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9840 - loss: 0.0563 - val_accuracy: 0.8888 - val_loss: 0.7047\n",
            "Epoch 87/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 18ms/step - accuracy: 0.9807 - loss: 0.0770 - val_accuracy: 0.8896 - val_loss: 0.6075\n",
            "Epoch 88/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9868 - loss: 0.0494 - val_accuracy: 0.8975 - val_loss: 0.6287\n",
            "Epoch 89/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9864 - loss: 0.0518 - val_accuracy: 0.8975 - val_loss: 0.5595\n",
            "Epoch 90/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9880 - loss: 0.0469 - val_accuracy: 0.9070 - val_loss: 0.5967\n",
            "Epoch 91/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9844 - loss: 0.0514 - val_accuracy: 0.9070 - val_loss: 0.6245\n",
            "Epoch 92/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9847 - loss: 0.0596 - val_accuracy: 0.8995 - val_loss: 0.6031\n",
            "Epoch 93/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.9868 - loss: 0.0537 - val_accuracy: 0.8924 - val_loss: 0.6877\n",
            "Epoch 94/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.9858 - loss: 0.0489 - val_accuracy: 0.8864 - val_loss: 0.7252\n",
            "Epoch 95/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9842 - loss: 0.0592 - val_accuracy: 0.8888 - val_loss: 0.8046\n",
            "Epoch 96/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9785 - loss: 0.0829 - val_accuracy: 0.8924 - val_loss: 0.7418\n",
            "Epoch 97/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9803 - loss: 0.0892 - val_accuracy: 0.9023 - val_loss: 0.6856\n",
            "Epoch 98/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9805 - loss: 0.0829 - val_accuracy: 0.8943 - val_loss: 0.5560\n",
            "Epoch 99/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9823 - loss: 0.0669 - val_accuracy: 0.8920 - val_loss: 0.7920\n",
            "Epoch 100/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9769 - loss: 0.1002 - val_accuracy: 0.8710 - val_loss: 0.6289\n",
            "Epoch 101/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9804 - loss: 0.0753 - val_accuracy: 0.8864 - val_loss: 0.7803\n",
            "Epoch 102/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9750 - loss: 0.0944 - val_accuracy: 0.8896 - val_loss: 0.7850\n",
            "Epoch 103/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9828 - loss: 0.0669 - val_accuracy: 0.8908 - val_loss: 0.7194\n",
            "Epoch 104/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9796 - loss: 0.0830 - val_accuracy: 0.9106 - val_loss: 0.5905\n",
            "Epoch 105/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9816 - loss: 0.0721 - val_accuracy: 0.8928 - val_loss: 0.7180\n",
            "Epoch 106/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9856 - loss: 0.0616 - val_accuracy: 0.8912 - val_loss: 0.7172\n",
            "Epoch 107/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.9780 - loss: 0.0845 - val_accuracy: 0.8635 - val_loss: 0.8655\n",
            "Epoch 108/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.9767 - loss: 0.0949 - val_accuracy: 0.8841 - val_loss: 0.7198\n",
            "Epoch 109/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9716 - loss: 0.1248 - val_accuracy: 0.8904 - val_loss: 0.6848\n",
            "Epoch 110/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - accuracy: 0.9808 - loss: 0.0777 - val_accuracy: 0.8848 - val_loss: 0.7364\n",
            "Epoch 111/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9813 - loss: 0.0736 - val_accuracy: 0.8916 - val_loss: 0.8320\n",
            "Epoch 112/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9770 - loss: 0.0984 - val_accuracy: 0.8864 - val_loss: 0.7153\n",
            "Epoch 113/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9720 - loss: 0.1210 - val_accuracy: 0.8900 - val_loss: 0.6093\n",
            "Epoch 114/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9756 - loss: 0.0937 - val_accuracy: 0.8575 - val_loss: 0.8165\n",
            "Epoch 115/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9703 - loss: 0.1310 - val_accuracy: 0.8746 - val_loss: 0.7324\n",
            "Epoch 116/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - accuracy: 0.9623 - loss: 0.1572 - val_accuracy: 0.8860 - val_loss: 0.6693\n",
            "Epoch 117/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9767 - loss: 0.0984 - val_accuracy: 0.8959 - val_loss: 0.6872\n",
            "Epoch 118/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9791 - loss: 0.0885 - val_accuracy: 0.8908 - val_loss: 0.7337\n",
            "Epoch 119/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9710 - loss: 0.1093 - val_accuracy: 0.8888 - val_loss: 0.7199\n",
            "Epoch 120/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9735 - loss: 0.1083 - val_accuracy: 0.8852 - val_loss: 0.7797\n",
            "Epoch 121/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9759 - loss: 0.1022 - val_accuracy: 0.9030 - val_loss: 0.6170\n",
            "Epoch 122/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9761 - loss: 0.1059 - val_accuracy: 0.8904 - val_loss: 0.5983\n",
            "Epoch 123/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.9777 - loss: 0.0899 - val_accuracy: 0.8825 - val_loss: 0.6321\n",
            "Epoch 124/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9767 - loss: 0.0932 - val_accuracy: 0.8825 - val_loss: 0.5913\n",
            "Epoch 125/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9699 - loss: 0.1267 - val_accuracy: 0.8769 - val_loss: 0.6648\n",
            "Epoch 126/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9674 - loss: 0.1455 - val_accuracy: 0.8841 - val_loss: 0.7560\n",
            "Epoch 127/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9591 - loss: 0.1803 - val_accuracy: 0.8892 - val_loss: 0.6086\n",
            "Epoch 128/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9784 - loss: 0.0911 - val_accuracy: 0.8908 - val_loss: 0.7839\n",
            "Epoch 129/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9674 - loss: 0.1698 - val_accuracy: 0.8809 - val_loss: 0.7495\n",
            "Epoch 130/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - accuracy: 0.9621 - loss: 0.1880 - val_accuracy: 0.8714 - val_loss: 0.6675\n",
            "Epoch 131/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.9670 - loss: 0.1354 - val_accuracy: 0.8844 - val_loss: 0.5900\n",
            "Epoch 132/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9706 - loss: 0.1279 - val_accuracy: 0.8623 - val_loss: 0.6617\n",
            "Epoch 133/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.9664 - loss: 0.1415 - val_accuracy: 0.8781 - val_loss: 0.6847\n",
            "Epoch 134/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9705 - loss: 0.1249 - val_accuracy: 0.8848 - val_loss: 0.6806\n",
            "Epoch 135/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9644 - loss: 0.1696 - val_accuracy: 0.8753 - val_loss: 0.7544\n",
            "Epoch 136/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9533 - loss: 0.2157 - val_accuracy: 0.8702 - val_loss: 0.6553\n",
            "Epoch 137/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9572 - loss: 0.1719 - val_accuracy: 0.8817 - val_loss: 0.7698\n",
            "Epoch 138/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9603 - loss: 0.1875 - val_accuracy: 0.8746 - val_loss: 0.6991\n",
            "Epoch 139/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9494 - loss: 0.2387 - val_accuracy: 0.8662 - val_loss: 0.5973\n",
            "Epoch 140/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9601 - loss: 0.1752 - val_accuracy: 0.8334 - val_loss: 0.7406\n",
            "Epoch 141/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9197 - loss: 0.3785 - val_accuracy: 0.8599 - val_loss: 0.6663\n",
            "Epoch 142/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9324 - loss: 0.2746 - val_accuracy: 0.8583 - val_loss: 0.7026\n",
            "Epoch 143/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9453 - loss: 0.2284 - val_accuracy: 0.8789 - val_loss: 0.6661\n",
            "Epoch 144/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9313 - loss: 0.2802 - val_accuracy: 0.8461 - val_loss: 0.8633\n",
            "Epoch 145/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9235 - loss: 0.3567 - val_accuracy: 0.8492 - val_loss: 0.7847\n",
            "Epoch 146/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9160 - loss: 0.3723 - val_accuracy: 0.8686 - val_loss: 0.6875\n",
            "Epoch 147/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9297 - loss: 0.3299 - val_accuracy: 0.8591 - val_loss: 0.7286\n",
            "Epoch 148/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9144 - loss: 0.4025 - val_accuracy: 0.7570 - val_loss: 0.9961\n",
            "Epoch 149/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.8753 - loss: 0.5076 - val_accuracy: 0.8465 - val_loss: 0.7676\n",
            "Epoch 150/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.9043 - loss: 0.4282 - val_accuracy: 0.8211 - val_loss: 0.6854\n",
            "Epoch 151/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.8973 - loss: 0.4339 - val_accuracy: 0.8678 - val_loss: 0.6572\n",
            "Epoch 152/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9127 - loss: 0.3762 - val_accuracy: 0.8275 - val_loss: 0.6714\n",
            "Epoch 153/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9073 - loss: 0.3984 - val_accuracy: 0.8639 - val_loss: 0.6134\n",
            "Epoch 154/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9267 - loss: 0.3229 - val_accuracy: 0.7748 - val_loss: 0.8442\n",
            "Epoch 155/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.8976 - loss: 0.4309 - val_accuracy: 0.8227 - val_loss: 0.7754\n",
            "Epoch 156/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - accuracy: 0.9009 - loss: 0.4437 - val_accuracy: 0.8017 - val_loss: 0.8341\n",
            "Epoch 157/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.8989 - loss: 0.4531 - val_accuracy: 0.8591 - val_loss: 0.7658\n",
            "Epoch 158/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9066 - loss: 0.4116 - val_accuracy: 0.8366 - val_loss: 0.7303\n",
            "Epoch 159/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9091 - loss: 0.3883 - val_accuracy: 0.6909 - val_loss: 1.1213\n",
            "Epoch 160/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.8787 - loss: 0.5447 - val_accuracy: 0.8037 - val_loss: 0.7606\n",
            "Epoch 161/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9026 - loss: 0.4300 - val_accuracy: 0.8101 - val_loss: 0.7642\n",
            "Epoch 162/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.8738 - loss: 0.5572 - val_accuracy: 0.8013 - val_loss: 0.8155\n",
            "Epoch 163/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.8561 - loss: 0.6088 - val_accuracy: 0.8520 - val_loss: 0.7396\n",
            "Epoch 164/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.8875 - loss: 0.5248 - val_accuracy: 0.8251 - val_loss: 0.7286\n",
            "Epoch 165/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.8791 - loss: 0.5213 - val_accuracy: 0.7665 - val_loss: 0.8828\n",
            "Epoch 166/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.8517 - loss: 0.6590 - val_accuracy: 0.7068 - val_loss: 1.1231\n",
            "Epoch 167/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.8233 - loss: 0.7945 - val_accuracy: 0.7748 - val_loss: 0.8315\n",
            "Epoch 168/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.8414 - loss: 0.6843 - val_accuracy: 0.8195 - val_loss: 0.8246\n",
            "Epoch 169/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.8113 - loss: 0.8313 - val_accuracy: 0.5916 - val_loss: 1.4432\n",
            "Epoch 170/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.8225 - loss: 0.7235 - val_accuracy: 0.7954 - val_loss: 0.8176\n",
            "Epoch 171/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - accuracy: 0.8396 - loss: 0.6939 - val_accuracy: 0.7194 - val_loss: 1.0379\n",
            "Epoch 172/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.8039 - loss: 0.8007 - val_accuracy: 0.8073 - val_loss: 0.7899\n",
            "Epoch 173/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.8390 - loss: 0.7295 - val_accuracy: 0.8176 - val_loss: 0.7428\n",
            "Epoch 174/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.8624 - loss: 0.5730 - val_accuracy: 0.7950 - val_loss: 0.9271\n",
            "Epoch 175/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.8238 - loss: 0.7416 - val_accuracy: 0.8354 - val_loss: 0.7523\n",
            "Epoch 176/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.8443 - loss: 0.6772 - val_accuracy: 0.7602 - val_loss: 0.9199\n",
            "Epoch 177/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.8420 - loss: 0.6401 - val_accuracy: 0.7907 - val_loss: 0.8565\n",
            "Epoch 178/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.8394 - loss: 0.6706 - val_accuracy: 0.7732 - val_loss: 0.9370\n",
            "Epoch 179/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.8474 - loss: 0.6762 - val_accuracy: 0.8124 - val_loss: 0.7809\n",
            "Epoch 180/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.8512 - loss: 0.6296 - val_accuracy: 0.8069 - val_loss: 0.7433\n",
            "Epoch 181/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.8331 - loss: 0.7301 - val_accuracy: 0.6799 - val_loss: 1.1306\n",
            "Epoch 182/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.7916 - loss: 0.8845 - val_accuracy: 0.7665 - val_loss: 0.9223\n",
            "Epoch 183/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.8274 - loss: 0.7263 - val_accuracy: 0.7847 - val_loss: 0.8709\n",
            "Epoch 184/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.8239 - loss: 0.7455 - val_accuracy: 0.7238 - val_loss: 1.0943\n",
            "Epoch 185/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.8123 - loss: 0.8042 - val_accuracy: 0.7907 - val_loss: 0.8446\n",
            "Epoch 186/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.7899 - loss: 0.8951 - val_accuracy: 0.7182 - val_loss: 1.0063\n",
            "Epoch 187/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.7526 - loss: 1.0678 - val_accuracy: 0.6589 - val_loss: 1.2306\n",
            "Epoch 188/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.7739 - loss: 0.9987 - val_accuracy: 0.7685 - val_loss: 0.9443\n",
            "Epoch 189/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.7763 - loss: 0.9839 - val_accuracy: 0.7903 - val_loss: 0.8396\n",
            "Epoch 190/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.7889 - loss: 0.8815 - val_accuracy: 0.6878 - val_loss: 1.1384\n",
            "Epoch 191/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.7566 - loss: 1.0692 - val_accuracy: 0.8049 - val_loss: 0.7836\n",
            "Epoch 192/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.8122 - loss: 0.7927 - val_accuracy: 0.7649 - val_loss: 0.9160\n",
            "Epoch 193/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.7894 - loss: 0.9042 - val_accuracy: 0.7527 - val_loss: 0.9337\n",
            "Epoch 194/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.7799 - loss: 0.8928 - val_accuracy: 0.7946 - val_loss: 0.8952\n",
            "Epoch 195/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - accuracy: 0.7983 - loss: 0.8776 - val_accuracy: 0.6945 - val_loss: 1.1633\n",
            "Epoch 196/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.7389 - loss: 1.1036 - val_accuracy: 0.7626 - val_loss: 0.9089\n",
            "Epoch 197/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.8254 - loss: 0.7341 - val_accuracy: 0.7713 - val_loss: 0.9248\n",
            "Epoch 198/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.7662 - loss: 0.9646 - val_accuracy: 0.7368 - val_loss: 1.0546\n",
            "Epoch 199/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.8033 - loss: 0.8078 - val_accuracy: 0.7523 - val_loss: 0.9418\n",
            "Epoch 200/200\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.7984 - loss: 0.8301 - val_accuracy: 0.6913 - val_loss: 1.2222\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "Training complete. Model saved to /content/drive/MyDrive/simpsons_classifier_final.h5.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.Backbone (ResNet)\n",
        "File: model_frcnn.py\n",
        "\n",
        "Function: nn_base(input_tensor=None, trainable=False)\n",
        "\n",
        "Purpose: Builds the convolutional layers (e.g., VGG16 without FC layers).\n",
        "\n",
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "\n",
        "def nn_base(input_tensor=None, trainable=False):\n",
        "    # Load pretrained VGG16 without top\n",
        "    base_model = VGG16(weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
        "    # Set layer trainability\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = trainable\n",
        "    return base_model.output\n",
        "\n",
        " 2.Region Proposal Network (RPN)\n",
        "File: model_frcnn.py\n",
        "\n",
        "Function: rpn(base_layers, num_anchors)\n",
        "\n",
        "Purpose: Adds RPN layers (classification + regression for anchors).\n",
        "\n",
        "\n",
        "##def rpn(base_layers, num_anchors):\n",
        "    x = Conv2D(512, (3,3), padding='same', activation='relu')(base_layers)\n",
        "    x_class = Conv2D(num_anchors, (1,1), activation='sigmoid')(x)\n",
        "    x_regr = Conv2D(num_anchors * 4, (1,1), activation='linear')(x)\n",
        "    return [x_class, x_regr, base_layers]\n",
        "\n",
        "3.RoI Pooling Layer\n",
        "File: roi_helpers.py or layers.py\n",
        "\n",
        "Function: RoiPoolingConv class (custom layer)\n",
        "\n",
        "Purpose: Converts each RoI to a fixed size feature map.\n",
        "\n",
        "##class RoiPoolingConv(Layer):\n",
        "    def __init__(self, pool_size, num_rois, **kwargs):\n",
        "        Custom RoI pooling layer\n",
        "\n",
        "4.Classifier & Regressor (Head)\n",
        "File: model_frcnn.py\n",
        "\n",
        "Function: classifier_layers(x, input_rois, num_rois, nb_classes)\n",
        "\n",
        "Purpose: Performs classification and bounding box regression on pooled RoIs.\n",
        "\n",
        "##def classifier_layers(base_layers, input_rois, num_rois, nb_classes=21):\n",
        "    Apply dense layers, softmax for class, linear for bbox regression\n",
        "\n",
        "5.Anchor Target Assignment, Loss Functions, Training Loop\n",
        "Files:\n",
        "\n",
        "losses.py: Contains rpn_loss_cls, rpn_loss_regr, class_loss_cls, class_loss_regr\n",
        "\n",
        "train_frcnn.py: Main training loop\n",
        "\n",
        "data_generators.py: Anchor labeling, IoU computation\n"
      ],
      "metadata": {
        "id": "g-6MMa1e4hXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "import os\n",
        "project_dir = \"/content/drive/MyDrive/Project Folder\"\n",
        "os.chdir(project_dir)\n",
        "\n",
        "if not os.path.exists(\"keras-yolo3\"):\n",
        "    !git clone https://github.com/qqwweee/keras-yolo3.git\n",
        "\n",
        "os.chdir(\"keras-yolo3\")\n",
        "\n",
        "cfg_path = \"/content/drive/MyDrive/Project Folder/yolov3.cfg\"\n",
        "if os.path.exists(cfg_path):\n",
        "    !cp \"{cfg_path}\" yolov3.cfg\n",
        "else:\n",
        "    raise FileNotFoundError(f\"Specified YOLOv3 config file not found: {cfg_path}\")\n",
        "weights_path = \"/content/drive/MyDrive/Project Folder/yolov3 (1).weights\"\n",
        "if os.path.exists(weights_path):\n",
        "    !cp \"{weights_path}\" yolov3.weights\n",
        "else:\n",
        "    raise FileNotFoundError(f\"Specified weights file not found: {weights_path}\")\n",
        "\n",
        "!find . -type f -name \"*.py\" -exec sed -i 's/from keras/from tensorflow.keras/g' {} +\n",
        "!find . -type f -name \"*.py\" -exec sed -i 's/import keras/import tensorflow.keras/g' {} +\n",
        "!find . -type f -name \"*.py\" -exec sed -i '/multi_gpu_model/d' {} +\n",
        "\n",
        "!python convert.py yolov3.cfg yolov3.weights model_data/yolo.h5\n",
        "\n",
        "if not os.path.exists(\"model_data/yolo.h5\"):\n",
        "    raise FileNotFoundError(\"Model conversion failed! 'model_data/yolo.h5' was not created.\")\n",
        "\n",
        "!python yolo_video.py --image --model model_data/yolo.h5\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sM5Z03er-COb",
        "outputId": "85c19646-4b34-4486-cc9f-f78a65683546"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "2025-05-26 00:06:43.707768: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1748218003.729998   34975 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1748218003.736752   34975 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-26 00:06:43.769505: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading weights.\n",
            "Weights Header: 0 2 0 [32013312]\n",
            "Parsing Darknet config.\n",
            "Creating Keras model.\n",
            "Parsing section net_0\n",
            "Parsing section convolutional_0\n",
            "Skipping weight assignment for convolutional_0 due to error: You called `set_weights(weights)` on layer 'conv2d' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "2025-05-26 00:06:48.627411: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1748218008.627575   34975 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "Skipping batch normalization for convolutional_0 due to error: You called `set_weights(weights)` on layer 'batch_normalization' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "  warnings.warn(\n",
            "Parsing section convolutional_1\n",
            "Skipping weight assignment for convolutional_1 due to error: You called `set_weights(weights)` on layer 'conv2d_1' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_1 due to error: You called `set_weights(weights)` on layer 'batch_normalization_1' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section convolutional_2\n",
            "Skipping weight assignment for convolutional_2 due to error: You called `set_weights(weights)` on layer 'conv2d_2' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_2 due to error: You called `set_weights(weights)` on layer 'batch_normalization_2' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section convolutional_3\n",
            "Skipping weight assignment for convolutional_3 due to error: You called `set_weights(weights)` on layer 'conv2d_3' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_3 due to error: You called `set_weights(weights)` on layer 'batch_normalization_3' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section shortcut_0\n",
            "Parsing section convolutional_4\n",
            "Skipping weight assignment for convolutional_4 due to error: You called `set_weights(weights)` on layer 'conv2d_4' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_4 due to error: You called `set_weights(weights)` on layer 'batch_normalization_4' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section convolutional_5\n",
            "Skipping weight assignment for convolutional_5 due to error: You called `set_weights(weights)` on layer 'conv2d_5' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_5 due to error: You called `set_weights(weights)` on layer 'batch_normalization_5' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section convolutional_6\n",
            "Skipping weight assignment for convolutional_6 due to error: You called `set_weights(weights)` on layer 'conv2d_6' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_6 due to error: You called `set_weights(weights)` on layer 'batch_normalization_6' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section shortcut_1\n",
            "Parsing section convolutional_7\n",
            "Skipping weight assignment for convolutional_7 due to error: You called `set_weights(weights)` on layer 'conv2d_7' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_7 due to error: You called `set_weights(weights)` on layer 'batch_normalization_7' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section convolutional_8\n",
            "Skipping weight assignment for convolutional_8 due to error: You called `set_weights(weights)` on layer 'conv2d_8' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_8 due to error: You called `set_weights(weights)` on layer 'batch_normalization_8' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section shortcut_2\n",
            "Parsing section convolutional_9\n",
            "Skipping weight assignment for convolutional_9 due to error: You called `set_weights(weights)` on layer 'conv2d_9' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_9 due to error: You called `set_weights(weights)` on layer 'batch_normalization_9' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section convolutional_10\n",
            "Skipping weight assignment for convolutional_10 due to error: You called `set_weights(weights)` on layer 'conv2d_10' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_10 due to error: You called `set_weights(weights)` on layer 'batch_normalization_10' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section convolutional_11\n",
            "Skipping weight assignment for convolutional_11 due to error: You called `set_weights(weights)` on layer 'conv2d_11' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_11 due to error: You called `set_weights(weights)` on layer 'batch_normalization_11' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section shortcut_3\n",
            "Parsing section convolutional_12\n",
            "Skipping weight assignment for convolutional_12 due to error: You called `set_weights(weights)` on layer 'conv2d_12' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_12 due to error: You called `set_weights(weights)` on layer 'batch_normalization_12' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section convolutional_13\n",
            "Skipping weight assignment for convolutional_13 due to error: You called `set_weights(weights)` on layer 'conv2d_13' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_13 due to error: You called `set_weights(weights)` on layer 'batch_normalization_13' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section shortcut_4\n",
            "Parsing section convolutional_14\n",
            "Skipping weight assignment for convolutional_14 due to error: You called `set_weights(weights)` on layer 'conv2d_14' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_14 due to error: You called `set_weights(weights)` on layer 'batch_normalization_14' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section convolutional_15\n",
            "Skipping weight assignment for convolutional_15 due to error: You called `set_weights(weights)` on layer 'conv2d_15' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_15 due to error: You called `set_weights(weights)` on layer 'batch_normalization_15' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section shortcut_5\n",
            "Parsing section convolutional_16\n",
            "Skipping weight assignment for convolutional_16 due to error: You called `set_weights(weights)` on layer 'conv2d_16' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_16 due to error: You called `set_weights(weights)` on layer 'batch_normalization_16' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section convolutional_17\n",
            "Skipping weight assignment for convolutional_17 due to error: You called `set_weights(weights)` on layer 'conv2d_17' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_17 due to error: You called `set_weights(weights)` on layer 'batch_normalization_17' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section shortcut_6\n",
            "Parsing section convolutional_18\n",
            "Skipping weight assignment for convolutional_18 due to error: You called `set_weights(weights)` on layer 'conv2d_18' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_18 due to error: You called `set_weights(weights)` on layer 'batch_normalization_18' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section convolutional_19\n",
            "Skipping weight assignment for convolutional_19 due to error: You called `set_weights(weights)` on layer 'conv2d_19' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_19 due to error: You called `set_weights(weights)` on layer 'batch_normalization_19' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section shortcut_7\n",
            "Parsing section convolutional_20\n",
            "Skipping weight assignment for convolutional_20 due to error: You called `set_weights(weights)` on layer 'conv2d_20' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_20 due to error: You called `set_weights(weights)` on layer 'batch_normalization_20' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section convolutional_21\n",
            "Skipping weight assignment for convolutional_21 due to error: You called `set_weights(weights)` on layer 'conv2d_21' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_21 due to error: You called `set_weights(weights)` on layer 'batch_normalization_21' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section shortcut_8\n",
            "Parsing section convolutional_22\n",
            "Skipping weight assignment for convolutional_22 due to error: You called `set_weights(weights)` on layer 'conv2d_22' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_22 due to error: You called `set_weights(weights)` on layer 'batch_normalization_22' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section convolutional_23\n",
            "Skipping weight assignment for convolutional_23 due to error: You called `set_weights(weights)` on layer 'conv2d_23' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_23 due to error: You called `set_weights(weights)` on layer 'batch_normalization_23' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section shortcut_9\n",
            "Parsing section convolutional_24\n",
            "Skipping weight assignment for convolutional_24 due to error: You called `set_weights(weights)` on layer 'conv2d_24' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_24 due to error: You called `set_weights(weights)` on layer 'batch_normalization_24' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section convolutional_25\n",
            "Skipping weight assignment for convolutional_25 due to error: You called `set_weights(weights)` on layer 'conv2d_25' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_25 due to error: You called `set_weights(weights)` on layer 'batch_normalization_25' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section shortcut_10\n",
            "Parsing section convolutional_26\n",
            "Skipping weight assignment for convolutional_26 due to error: You called `set_weights(weights)` on layer 'conv2d_26' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_26 due to error: You called `set_weights(weights)` on layer 'batch_normalization_26' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section convolutional_27\n",
            "Skipping weight assignment for convolutional_27 due to error: You called `set_weights(weights)` on layer 'conv2d_27' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_27 due to error: You called `set_weights(weights)` on layer 'batch_normalization_27' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section convolutional_28\n",
            "Skipping weight assignment for convolutional_28 due to error: You called `set_weights(weights)` on layer 'conv2d_28' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_28 due to error: You called `set_weights(weights)` on layer 'batch_normalization_28' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section shortcut_11\n",
            "Parsing section convolutional_29\n",
            "Skipping weight assignment for convolutional_29 due to error: You called `set_weights(weights)` on layer 'conv2d_29' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_29 due to error: You called `set_weights(weights)` on layer 'batch_normalization_29' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section convolutional_30\n",
            "Skipping weight assignment for convolutional_30 due to error: You called `set_weights(weights)` on layer 'conv2d_30' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_30 due to error: You called `set_weights(weights)` on layer 'batch_normalization_30' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section shortcut_12\n",
            "Parsing section convolutional_31\n",
            "Skipping weight assignment for convolutional_31 due to error: You called `set_weights(weights)` on layer 'conv2d_31' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_31 due to error: You called `set_weights(weights)` on layer 'batch_normalization_31' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section convolutional_32\n",
            "Skipping weight assignment for convolutional_32 due to error: You called `set_weights(weights)` on layer 'conv2d_32' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_32 due to error: You called `set_weights(weights)` on layer 'batch_normalization_32' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section shortcut_13\n",
            "Parsing section convolutional_33\n",
            "Skipping weight assignment for convolutional_33 due to error: You called `set_weights(weights)` on layer 'conv2d_33' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_33 due to error: You called `set_weights(weights)` on layer 'batch_normalization_33' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section convolutional_34\n",
            "Skipping weight assignment for convolutional_34 due to error: You called `set_weights(weights)` on layer 'conv2d_34' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_34 due to error: You called `set_weights(weights)` on layer 'batch_normalization_34' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section shortcut_14\n",
            "Parsing section convolutional_35\n",
            "Skipping weight assignment for convolutional_35 due to error: You called `set_weights(weights)` on layer 'conv2d_35' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_35 due to error: You called `set_weights(weights)` on layer 'batch_normalization_35' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section convolutional_36\n",
            "Skipping weight assignment for convolutional_36 due to error: You called `set_weights(weights)` on layer 'conv2d_36' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_36 due to error: You called `set_weights(weights)` on layer 'batch_normalization_36' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section shortcut_15\n",
            "Parsing section convolutional_37\n",
            "Skipping weight assignment for convolutional_37 due to error: You called `set_weights(weights)` on layer 'conv2d_37' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_37 due to error: You called `set_weights(weights)` on layer 'batch_normalization_37' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section convolutional_38\n",
            "Skipping weight assignment for convolutional_38 due to error: You called `set_weights(weights)` on layer 'conv2d_38' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_38 due to error: You called `set_weights(weights)` on layer 'batch_normalization_38' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section shortcut_16\n",
            "Parsing section convolutional_39\n",
            "Skipping weight assignment for convolutional_39 due to error: You called `set_weights(weights)` on layer 'conv2d_39' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_39 due to error: You called `set_weights(weights)` on layer 'batch_normalization_39' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section convolutional_40\n",
            "Skipping weight assignment for convolutional_40 due to error: You called `set_weights(weights)` on layer 'conv2d_40' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_40 due to error: You called `set_weights(weights)` on layer 'batch_normalization_40' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section shortcut_17\n",
            "Parsing section convolutional_41\n",
            "Skipping weight assignment for convolutional_41 due to error: You called `set_weights(weights)` on layer 'conv2d_41' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_41 due to error: You called `set_weights(weights)` on layer 'batch_normalization_41' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section convolutional_42\n",
            "Skipping weight assignment for convolutional_42 due to error: You called `set_weights(weights)` on layer 'conv2d_42' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_42 due to error: You called `set_weights(weights)` on layer 'batch_normalization_42' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section shortcut_18\n",
            "Parsing section convolutional_43\n",
            "Skipping weight assignment for convolutional_43 due to error: You called `set_weights(weights)` on layer 'conv2d_43' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_43 due to error: You called `set_weights(weights)` on layer 'batch_normalization_43' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section convolutional_44\n",
            "Skipping weight assignment for convolutional_44 due to error: You called `set_weights(weights)` on layer 'conv2d_44' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_44 due to error: You called `set_weights(weights)` on layer 'batch_normalization_44' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section convolutional_45\n",
            "Skipping weight assignment for convolutional_45 due to error: You called `set_weights(weights)` on layer 'conv2d_45' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_45 due to error: You called `set_weights(weights)` on layer 'batch_normalization_45' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section shortcut_19\n",
            "Parsing section convolutional_46\n",
            "Skipping weight assignment for convolutional_46 due to error: You called `set_weights(weights)` on layer 'conv2d_46' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_46 due to error: You called `set_weights(weights)` on layer 'batch_normalization_46' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section convolutional_47\n",
            "Skipping weight assignment for convolutional_47 due to error: You called `set_weights(weights)` on layer 'conv2d_47' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_47 due to error: You called `set_weights(weights)` on layer 'batch_normalization_47' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section shortcut_20\n",
            "Parsing section convolutional_48\n",
            "Skipping weight assignment for convolutional_48 due to error: You called `set_weights(weights)` on layer 'conv2d_48' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_48 due to error: You called `set_weights(weights)` on layer 'batch_normalization_48' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section convolutional_49\n",
            "Skipping weight assignment for convolutional_49 due to error: You called `set_weights(weights)` on layer 'conv2d_49' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_49 due to error: You called `set_weights(weights)` on layer 'batch_normalization_49' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section shortcut_21\n",
            "Parsing section convolutional_50\n",
            "Skipping weight assignment for convolutional_50 due to error: You called `set_weights(weights)` on layer 'conv2d_50' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_50 due to error: You called `set_weights(weights)` on layer 'batch_normalization_50' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section convolutional_51\n",
            "Skipping weight assignment for convolutional_51 due to error: You called `set_weights(weights)` on layer 'conv2d_51' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_51 due to error: You called `set_weights(weights)` on layer 'batch_normalization_51' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section shortcut_22\n",
            "Parsing section convolutional_52\n",
            "Skipping weight assignment for convolutional_52 due to error: You called `set_weights(weights)` on layer 'conv2d_52' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_52 due to error: You called `set_weights(weights)` on layer 'batch_normalization_52' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section convolutional_53\n",
            "Skipping weight assignment for convolutional_53 due to error: You called `set_weights(weights)` on layer 'conv2d_53' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_53 due to error: You called `set_weights(weights)` on layer 'batch_normalization_53' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section convolutional_54\n",
            "Skipping weight assignment for convolutional_54 due to error: You called `set_weights(weights)` on layer 'conv2d_54' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_54 due to error: You called `set_weights(weights)` on layer 'batch_normalization_54' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section convolutional_55\n",
            "Skipping weight assignment for convolutional_55 due to error: You called `set_weights(weights)` on layer 'conv2d_55' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_55 due to error: You called `set_weights(weights)` on layer 'batch_normalization_55' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section convolutional_56\n",
            "Skipping weight assignment for convolutional_56 due to error: You called `set_weights(weights)` on layer 'conv2d_56' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_56 due to error: You called `set_weights(weights)` on layer 'batch_normalization_56' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section convolutional_57\n",
            "Skipping weight assignment for convolutional_57 due to error: You called `set_weights(weights)` on layer 'conv2d_57' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_57 due to error: You called `set_weights(weights)` on layer 'batch_normalization_57' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section convolutional_58\n",
            "Skipping weight assignment for convolutional_58 due to error: You called `set_weights(weights)` on layer 'conv2d_58' with a weight list of length 2, but the layer was expecting 0 weights.\n",
            "Parsing section yolo_0\n",
            "Parsing section route_0\n",
            "Parsing section convolutional_59\n",
            "Skipping weight assignment for convolutional_59 due to error: You called `set_weights(weights)` on layer 'conv2d_59' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_59 due to error: You called `set_weights(weights)` on layer 'batch_normalization_58' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section upsample_0\n",
            "Parsing section route_1\n",
            "Parsing section convolutional_60\n",
            "Skipping weight assignment for convolutional_60 due to error: You called `set_weights(weights)` on layer 'conv2d_60' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_60 due to error: You called `set_weights(weights)` on layer 'batch_normalization_59' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section convolutional_61\n",
            "Skipping weight assignment for convolutional_61 due to error: You called `set_weights(weights)` on layer 'conv2d_61' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_61 due to error: You called `set_weights(weights)` on layer 'batch_normalization_60' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section convolutional_62\n",
            "Skipping weight assignment for convolutional_62 due to error: You called `set_weights(weights)` on layer 'conv2d_62' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_62 due to error: You called `set_weights(weights)` on layer 'batch_normalization_61' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section convolutional_63\n",
            "Skipping weight assignment for convolutional_63 due to error: You called `set_weights(weights)` on layer 'conv2d_63' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_63 due to error: You called `set_weights(weights)` on layer 'batch_normalization_62' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section convolutional_64\n",
            "Skipping weight assignment for convolutional_64 due to error: You called `set_weights(weights)` on layer 'conv2d_64' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_64 due to error: You called `set_weights(weights)` on layer 'batch_normalization_63' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section convolutional_65\n",
            "Skipping weight assignment for convolutional_65 due to error: You called `set_weights(weights)` on layer 'conv2d_65' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_65 due to error: You called `set_weights(weights)` on layer 'batch_normalization_64' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section convolutional_66\n",
            "Skipping weight assignment for convolutional_66 due to error: You called `set_weights(weights)` on layer 'conv2d_66' with a weight list of length 2, but the layer was expecting 0 weights.\n",
            "Parsing section yolo_1\n",
            "Parsing section route_2\n",
            "Parsing section convolutional_67\n",
            "Skipping weight assignment for convolutional_67 due to error: You called `set_weights(weights)` on layer 'conv2d_67' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_67 due to error: You called `set_weights(weights)` on layer 'batch_normalization_65' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section upsample_1\n",
            "Parsing section route_3\n",
            "Parsing section convolutional_68\n",
            "Skipping weight assignment for convolutional_68 due to error: You called `set_weights(weights)` on layer 'conv2d_68' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_68 due to error: You called `set_weights(weights)` on layer 'batch_normalization_66' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section convolutional_69\n",
            "Skipping weight assignment for convolutional_69 due to error: You called `set_weights(weights)` on layer 'conv2d_69' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_69 due to error: You called `set_weights(weights)` on layer 'batch_normalization_67' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section convolutional_70\n",
            "Skipping weight assignment for convolutional_70 due to error: You called `set_weights(weights)` on layer 'conv2d_70' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_70 due to error: You called `set_weights(weights)` on layer 'batch_normalization_68' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section convolutional_71\n",
            "Skipping weight assignment for convolutional_71 due to error: You called `set_weights(weights)` on layer 'conv2d_71' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_71 due to error: You called `set_weights(weights)` on layer 'batch_normalization_69' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section convolutional_72\n",
            "Skipping weight assignment for convolutional_72 due to error: You called `set_weights(weights)` on layer 'conv2d_72' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_72 due to error: You called `set_weights(weights)` on layer 'batch_normalization_70' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section convolutional_73\n",
            "Skipping weight assignment for convolutional_73 due to error: You called `set_weights(weights)` on layer 'conv2d_73' with a weight list of length 1, but the layer was expecting 0 weights.\n",
            "Skipping batch normalization for convolutional_73 due to error: You called `set_weights(weights)` on layer 'batch_normalization_71' with a weight list of length 4, but the layer was expecting 0 weights.\n",
            "Parsing section convolutional_74\n",
            "Skipping weight assignment for convolutional_74 due to error: You called `set_weights(weights)` on layer 'conv2d_74' with a weight list of length 2, but the layer was expecting 0 weights.\n",
            "Parsing section yolo_2\n",
            "\u001b[1mModel: \"functional\"\u001b[0m\n",
            "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
            "│ input_layer         │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ -                 │\n",
            "│ (\u001b[94mInputLayer\u001b[0m)        │ \u001b[96mNone\u001b[0m, \u001b[32m3\u001b[0m)          │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d (\u001b[94mConv2D\u001b[0m)     │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │        \u001b[32m864\u001b[0m │ input_layer[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m] │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m)         │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalization │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │        \u001b[32m128\u001b[0m │ conv2d[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m)         │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu         │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m)         │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ zero_padding2d      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ leaky_re_lu[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m] │\n",
            "│ (\u001b[94mZeroPadding2D\u001b[0m)     │ \u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m)         │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_1 (\u001b[94mConv2D\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │     \u001b[32m18,432\u001b[0m │ zero_padding2d[\u001b[32m0\u001b[0m… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m)         │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │        \u001b[32m256\u001b[0m │ conv2d_1[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m)         │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_1       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m)         │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_2 (\u001b[94mConv2D\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m2,048\u001b[0m │ leaky_re_lu_1[\u001b[32m0\u001b[0m]… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m)         │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │        \u001b[32m128\u001b[0m │ conv2d_2[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m)         │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_2       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m)         │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_3 (\u001b[94mConv2D\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │     \u001b[32m18,432\u001b[0m │ leaky_re_lu_2[\u001b[32m0\u001b[0m]… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m)         │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │        \u001b[32m256\u001b[0m │ conv2d_3[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m)         │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_3       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m)         │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ add (\u001b[94mAdd\u001b[0m)           │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ leaky_re_lu_1[\u001b[32m0\u001b[0m]… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m)         │            │ leaky_re_lu_3[\u001b[32m0\u001b[0m]… │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ zero_padding2d_1    │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ add[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]         │\n",
            "│ (\u001b[94mZeroPadding2D\u001b[0m)     │ \u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m)         │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_4 (\u001b[94mConv2D\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │     \u001b[32m73,728\u001b[0m │ zero_padding2d_1… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │        \u001b[32m512\u001b[0m │ conv2d_4[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_4       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_5 (\u001b[94mConv2D\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m8,192\u001b[0m │ leaky_re_lu_4[\u001b[32m0\u001b[0m]… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m)         │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │        \u001b[32m256\u001b[0m │ conv2d_5[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m)         │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_5       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m)         │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_6 (\u001b[94mConv2D\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │     \u001b[32m73,728\u001b[0m │ leaky_re_lu_5[\u001b[32m0\u001b[0m]… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │        \u001b[32m512\u001b[0m │ conv2d_6[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_6       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ add_1 (\u001b[94mAdd\u001b[0m)         │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ leaky_re_lu_4[\u001b[32m0\u001b[0m]… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)        │            │ leaky_re_lu_6[\u001b[32m0\u001b[0m]… │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_7 (\u001b[94mConv2D\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m8,192\u001b[0m │ add_1[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]       │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m)         │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │        \u001b[32m256\u001b[0m │ conv2d_7[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m)         │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_7       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m)         │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_8 (\u001b[94mConv2D\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │     \u001b[32m73,728\u001b[0m │ leaky_re_lu_7[\u001b[32m0\u001b[0m]… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │        \u001b[32m512\u001b[0m │ conv2d_8[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_8       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ add_2 (\u001b[94mAdd\u001b[0m)         │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ add_1[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],      │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)        │            │ leaky_re_lu_8[\u001b[32m0\u001b[0m]… │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ zero_padding2d_2    │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ add_2[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]       │\n",
            "│ (\u001b[94mZeroPadding2D\u001b[0m)     │ \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_9 (\u001b[94mConv2D\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │    \u001b[32m294,912\u001b[0m │ zero_padding2d_2… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m1,024\u001b[0m │ conv2d_9[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_9       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_10 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │     \u001b[32m32,768\u001b[0m │ leaky_re_lu_9[\u001b[32m0\u001b[0m]… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │        \u001b[32m512\u001b[0m │ conv2d_10[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_10      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_11 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │    \u001b[32m294,912\u001b[0m │ leaky_re_lu_10[\u001b[32m0\u001b[0m… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m1,024\u001b[0m │ conv2d_11[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_11      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ add_3 (\u001b[94mAdd\u001b[0m)         │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ leaky_re_lu_9[\u001b[32m0\u001b[0m]… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │ leaky_re_lu_11[\u001b[32m0\u001b[0m… │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_12 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │     \u001b[32m32,768\u001b[0m │ add_3[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]       │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │        \u001b[32m512\u001b[0m │ conv2d_12[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_12      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_13 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │    \u001b[32m294,912\u001b[0m │ leaky_re_lu_12[\u001b[32m0\u001b[0m… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m1,024\u001b[0m │ conv2d_13[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_13      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ add_4 (\u001b[94mAdd\u001b[0m)         │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ add_3[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],      │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │ leaky_re_lu_13[\u001b[32m0\u001b[0m… │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_14 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │     \u001b[32m32,768\u001b[0m │ add_4[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]       │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │        \u001b[32m512\u001b[0m │ conv2d_14[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_14      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_15 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │    \u001b[32m294,912\u001b[0m │ leaky_re_lu_14[\u001b[32m0\u001b[0m… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m1,024\u001b[0m │ conv2d_15[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_15      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ add_5 (\u001b[94mAdd\u001b[0m)         │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ add_4[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],      │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │ leaky_re_lu_15[\u001b[32m0\u001b[0m… │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_16 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │     \u001b[32m32,768\u001b[0m │ add_5[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]       │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │        \u001b[32m512\u001b[0m │ conv2d_16[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_16      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_17 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │    \u001b[32m294,912\u001b[0m │ leaky_re_lu_16[\u001b[32m0\u001b[0m… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m1,024\u001b[0m │ conv2d_17[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_17      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ add_6 (\u001b[94mAdd\u001b[0m)         │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ add_5[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],      │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │ leaky_re_lu_17[\u001b[32m0\u001b[0m… │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_18 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │     \u001b[32m32,768\u001b[0m │ add_6[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]       │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │        \u001b[32m512\u001b[0m │ conv2d_18[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_18      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_19 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │    \u001b[32m294,912\u001b[0m │ leaky_re_lu_18[\u001b[32m0\u001b[0m… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m1,024\u001b[0m │ conv2d_19[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_19      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ add_7 (\u001b[94mAdd\u001b[0m)         │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ add_6[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],      │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │ leaky_re_lu_19[\u001b[32m0\u001b[0m… │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_20 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │     \u001b[32m32,768\u001b[0m │ add_7[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]       │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │        \u001b[32m512\u001b[0m │ conv2d_20[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_20      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_21 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │    \u001b[32m294,912\u001b[0m │ leaky_re_lu_20[\u001b[32m0\u001b[0m… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m1,024\u001b[0m │ conv2d_21[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_21      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ add_8 (\u001b[94mAdd\u001b[0m)         │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ add_7[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],      │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │ leaky_re_lu_21[\u001b[32m0\u001b[0m… │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_22 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │     \u001b[32m32,768\u001b[0m │ add_8[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]       │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │        \u001b[32m512\u001b[0m │ conv2d_22[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_22      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_23 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │    \u001b[32m294,912\u001b[0m │ leaky_re_lu_22[\u001b[32m0\u001b[0m… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m1,024\u001b[0m │ conv2d_23[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_23      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ add_9 (\u001b[94mAdd\u001b[0m)         │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ add_8[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],      │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │ leaky_re_lu_23[\u001b[32m0\u001b[0m… │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_24 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │     \u001b[32m32,768\u001b[0m │ add_9[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]       │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │        \u001b[32m512\u001b[0m │ conv2d_24[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_24      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_25 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │    \u001b[32m294,912\u001b[0m │ leaky_re_lu_24[\u001b[32m0\u001b[0m… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m1,024\u001b[0m │ conv2d_25[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_25      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ add_10 (\u001b[94mAdd\u001b[0m)        │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ add_9[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],      │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │ leaky_re_lu_25[\u001b[32m0\u001b[0m… │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ zero_padding2d_3    │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ add_10[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n",
            "│ (\u001b[94mZeroPadding2D\u001b[0m)     │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_26 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │  \u001b[32m1,179,648\u001b[0m │ zero_padding2d_3… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m2,048\u001b[0m │ conv2d_26[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_26      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_27 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │    \u001b[32m131,072\u001b[0m │ leaky_re_lu_26[\u001b[32m0\u001b[0m… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m1,024\u001b[0m │ conv2d_27[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_27      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_28 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │  \u001b[32m1,179,648\u001b[0m │ leaky_re_lu_27[\u001b[32m0\u001b[0m… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m2,048\u001b[0m │ conv2d_28[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_28      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ add_11 (\u001b[94mAdd\u001b[0m)        │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ leaky_re_lu_26[\u001b[32m0\u001b[0m… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │ leaky_re_lu_28[\u001b[32m0\u001b[0m… │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_29 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │    \u001b[32m131,072\u001b[0m │ add_11[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m1,024\u001b[0m │ conv2d_29[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_29      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_30 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │  \u001b[32m1,179,648\u001b[0m │ leaky_re_lu_29[\u001b[32m0\u001b[0m… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m2,048\u001b[0m │ conv2d_30[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_30      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ add_12 (\u001b[94mAdd\u001b[0m)        │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ add_11[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],     │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │ leaky_re_lu_30[\u001b[32m0\u001b[0m… │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_31 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │    \u001b[32m131,072\u001b[0m │ add_12[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m1,024\u001b[0m │ conv2d_31[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_31      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_32 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │  \u001b[32m1,179,648\u001b[0m │ leaky_re_lu_31[\u001b[32m0\u001b[0m… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m2,048\u001b[0m │ conv2d_32[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_32      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ add_13 (\u001b[94mAdd\u001b[0m)        │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ add_12[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],     │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │ leaky_re_lu_32[\u001b[32m0\u001b[0m… │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_33 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │    \u001b[32m131,072\u001b[0m │ add_13[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m1,024\u001b[0m │ conv2d_33[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_33      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_34 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │  \u001b[32m1,179,648\u001b[0m │ leaky_re_lu_33[\u001b[32m0\u001b[0m… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m2,048\u001b[0m │ conv2d_34[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_34      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ add_14 (\u001b[94mAdd\u001b[0m)        │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ add_13[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],     │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │ leaky_re_lu_34[\u001b[32m0\u001b[0m… │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_35 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │    \u001b[32m131,072\u001b[0m │ add_14[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m1,024\u001b[0m │ conv2d_35[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_35      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_36 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │  \u001b[32m1,179,648\u001b[0m │ leaky_re_lu_35[\u001b[32m0\u001b[0m… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m2,048\u001b[0m │ conv2d_36[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_36      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ add_15 (\u001b[94mAdd\u001b[0m)        │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ add_14[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],     │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │ leaky_re_lu_36[\u001b[32m0\u001b[0m… │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_37 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │    \u001b[32m131,072\u001b[0m │ add_15[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m1,024\u001b[0m │ conv2d_37[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_37      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_38 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │  \u001b[32m1,179,648\u001b[0m │ leaky_re_lu_37[\u001b[32m0\u001b[0m… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m2,048\u001b[0m │ conv2d_38[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_38      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ add_16 (\u001b[94mAdd\u001b[0m)        │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ add_15[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],     │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │ leaky_re_lu_38[\u001b[32m0\u001b[0m… │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_39 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │    \u001b[32m131,072\u001b[0m │ add_16[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m1,024\u001b[0m │ conv2d_39[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_39      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_40 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │  \u001b[32m1,179,648\u001b[0m │ leaky_re_lu_39[\u001b[32m0\u001b[0m… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m2,048\u001b[0m │ conv2d_40[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_40      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ add_17 (\u001b[94mAdd\u001b[0m)        │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ add_16[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],     │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │ leaky_re_lu_40[\u001b[32m0\u001b[0m… │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_41 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │    \u001b[32m131,072\u001b[0m │ add_17[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m1,024\u001b[0m │ conv2d_41[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_41      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_42 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │  \u001b[32m1,179,648\u001b[0m │ leaky_re_lu_41[\u001b[32m0\u001b[0m… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m2,048\u001b[0m │ conv2d_42[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_42      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ add_18 (\u001b[94mAdd\u001b[0m)        │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ add_17[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],     │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │ leaky_re_lu_42[\u001b[32m0\u001b[0m… │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ zero_padding2d_4    │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ add_18[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n",
            "│ (\u001b[94mZeroPadding2D\u001b[0m)     │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_43 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │  \u001b[32m4,718,592\u001b[0m │ zero_padding2d_4… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m1024\u001b[0m)       │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m4,096\u001b[0m │ conv2d_43[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m1024\u001b[0m)       │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_43      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m1024\u001b[0m)       │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_44 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │    \u001b[32m524,288\u001b[0m │ leaky_re_lu_43[\u001b[32m0\u001b[0m… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m2,048\u001b[0m │ conv2d_44[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_44      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_45 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │  \u001b[32m4,718,592\u001b[0m │ leaky_re_lu_44[\u001b[32m0\u001b[0m… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m1024\u001b[0m)       │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m4,096\u001b[0m │ conv2d_45[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m1024\u001b[0m)       │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_45      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m1024\u001b[0m)       │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ add_19 (\u001b[94mAdd\u001b[0m)        │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ leaky_re_lu_43[\u001b[32m0\u001b[0m… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m1024\u001b[0m)       │            │ leaky_re_lu_45[\u001b[32m0\u001b[0m… │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_46 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │    \u001b[32m524,288\u001b[0m │ add_19[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m2,048\u001b[0m │ conv2d_46[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_46      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_47 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │  \u001b[32m4,718,592\u001b[0m │ leaky_re_lu_46[\u001b[32m0\u001b[0m… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m1024\u001b[0m)       │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m4,096\u001b[0m │ conv2d_47[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m1024\u001b[0m)       │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_47      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m1024\u001b[0m)       │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ add_20 (\u001b[94mAdd\u001b[0m)        │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ add_19[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],     │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m1024\u001b[0m)       │            │ leaky_re_lu_47[\u001b[32m0\u001b[0m… │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_48 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │    \u001b[32m524,288\u001b[0m │ add_20[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m2,048\u001b[0m │ conv2d_48[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_48      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_49 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │  \u001b[32m4,718,592\u001b[0m │ leaky_re_lu_48[\u001b[32m0\u001b[0m… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m1024\u001b[0m)       │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m4,096\u001b[0m │ conv2d_49[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m1024\u001b[0m)       │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_49      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m1024\u001b[0m)       │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ add_21 (\u001b[94mAdd\u001b[0m)        │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ add_20[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],     │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m1024\u001b[0m)       │            │ leaky_re_lu_49[\u001b[32m0\u001b[0m… │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_50 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │    \u001b[32m524,288\u001b[0m │ add_21[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m2,048\u001b[0m │ conv2d_50[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_50      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_51 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │  \u001b[32m4,718,592\u001b[0m │ leaky_re_lu_50[\u001b[32m0\u001b[0m… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m1024\u001b[0m)       │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m4,096\u001b[0m │ conv2d_51[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m1024\u001b[0m)       │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_51      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m1024\u001b[0m)       │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ add_22 (\u001b[94mAdd\u001b[0m)        │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ add_21[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],     │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m1024\u001b[0m)       │            │ leaky_re_lu_51[\u001b[32m0\u001b[0m… │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_52 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │    \u001b[32m524,288\u001b[0m │ add_22[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m2,048\u001b[0m │ conv2d_52[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_52      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_53 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │  \u001b[32m4,718,592\u001b[0m │ leaky_re_lu_52[\u001b[32m0\u001b[0m… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m1024\u001b[0m)       │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m4,096\u001b[0m │ conv2d_53[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m1024\u001b[0m)       │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_53      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m1024\u001b[0m)       │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_54 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │    \u001b[32m524,288\u001b[0m │ leaky_re_lu_53[\u001b[32m0\u001b[0m… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m2,048\u001b[0m │ conv2d_54[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_54      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_55 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │  \u001b[32m4,718,592\u001b[0m │ leaky_re_lu_54[\u001b[32m0\u001b[0m… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m1024\u001b[0m)       │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m4,096\u001b[0m │ conv2d_55[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m1024\u001b[0m)       │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_55      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m1024\u001b[0m)       │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_56 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │    \u001b[32m524,288\u001b[0m │ leaky_re_lu_55[\u001b[32m0\u001b[0m… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m2,048\u001b[0m │ conv2d_56[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_56      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_59 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │    \u001b[32m131,072\u001b[0m │ leaky_re_lu_56[\u001b[32m0\u001b[0m… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m1,024\u001b[0m │ conv2d_59[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_58      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ up_sampling2d       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ leaky_re_lu_58[\u001b[32m0\u001b[0m… │\n",
            "│ (\u001b[94mUpSampling2D\u001b[0m)      │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ concatenate         │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ up_sampling2d[\u001b[32m0\u001b[0m]… │\n",
            "│ (\u001b[94mConcatenate\u001b[0m)       │ \u001b[96mNone\u001b[0m, \u001b[32m768\u001b[0m)        │            │ add_18[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_60 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │    \u001b[32m196,608\u001b[0m │ concatenate[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m] │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m1,024\u001b[0m │ conv2d_60[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_59      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_61 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │  \u001b[32m1,179,648\u001b[0m │ leaky_re_lu_59[\u001b[32m0\u001b[0m… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m2,048\u001b[0m │ conv2d_61[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_60      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_62 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │    \u001b[32m131,072\u001b[0m │ leaky_re_lu_60[\u001b[32m0\u001b[0m… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m1,024\u001b[0m │ conv2d_62[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_61      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_63 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │  \u001b[32m1,179,648\u001b[0m │ leaky_re_lu_61[\u001b[32m0\u001b[0m… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m2,048\u001b[0m │ conv2d_63[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_62      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_64 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │    \u001b[32m131,072\u001b[0m │ leaky_re_lu_62[\u001b[32m0\u001b[0m… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m1,024\u001b[0m │ conv2d_64[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_63      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_67 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │     \u001b[32m32,768\u001b[0m │ leaky_re_lu_63[\u001b[32m0\u001b[0m… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │        \u001b[32m512\u001b[0m │ conv2d_67[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_65      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ up_sampling2d_1     │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ leaky_re_lu_65[\u001b[32m0\u001b[0m… │\n",
            "│ (\u001b[94mUpSampling2D\u001b[0m)      │ \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ concatenate_1       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ up_sampling2d_1[\u001b[32m…\u001b[0m │\n",
            "│ (\u001b[94mConcatenate\u001b[0m)       │ \u001b[96mNone\u001b[0m, \u001b[32m384\u001b[0m)        │            │ add_10[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_68 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │     \u001b[32m49,152\u001b[0m │ concatenate_1[\u001b[32m0\u001b[0m]… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │        \u001b[32m512\u001b[0m │ conv2d_68[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_66      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_69 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │    \u001b[32m294,912\u001b[0m │ leaky_re_lu_66[\u001b[32m0\u001b[0m… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m1,024\u001b[0m │ conv2d_69[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_67      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_70 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │     \u001b[32m32,768\u001b[0m │ leaky_re_lu_67[\u001b[32m0\u001b[0m… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │        \u001b[32m512\u001b[0m │ conv2d_70[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_68      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_71 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │    \u001b[32m294,912\u001b[0m │ leaky_re_lu_68[\u001b[32m0\u001b[0m… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m1,024\u001b[0m │ conv2d_71[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_69      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_72 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │     \u001b[32m32,768\u001b[0m │ leaky_re_lu_69[\u001b[32m0\u001b[0m… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │        \u001b[32m512\u001b[0m │ conv2d_72[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_70      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_57 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │  \u001b[32m4,718,592\u001b[0m │ leaky_re_lu_56[\u001b[32m0\u001b[0m… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m1024\u001b[0m)       │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_65 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │  \u001b[32m1,179,648\u001b[0m │ leaky_re_lu_63[\u001b[32m0\u001b[0m… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_73 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │    \u001b[32m294,912\u001b[0m │ leaky_re_lu_70[\u001b[32m0\u001b[0m… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m4,096\u001b[0m │ conv2d_57[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m1024\u001b[0m)       │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m2,048\u001b[0m │ conv2d_65[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ batch_normalizatio… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │      \u001b[32m1,024\u001b[0m │ conv2d_73[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
            "│ (\u001b[94mBatchNormalizatio…\u001b[0m │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_57      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m1024\u001b[0m)       │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_64      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m512\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ leaky_re_lu_71      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
            "│ (\u001b[94mLeakyReLU\u001b[0m)         │ \u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_58 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │    \u001b[32m261,375\u001b[0m │ leaky_re_lu_57[\u001b[32m0\u001b[0m… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m255\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_66 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │    \u001b[32m130,815\u001b[0m │ leaky_re_lu_64[\u001b[32m0\u001b[0m… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m255\u001b[0m)        │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ conv2d_74 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      │     \u001b[32m65,535\u001b[0m │ leaky_re_lu_71[\u001b[32m0\u001b[0m… │\n",
            "│                     │ \u001b[96mNone\u001b[0m, \u001b[32m255\u001b[0m)        │            │                   │\n",
            "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
            "\u001b[1m Total params: \u001b[0m\u001b[32m62,001,757\u001b[0m (236.52 MB)\n",
            "\u001b[1m Trainable params: \u001b[0m\u001b[32m61,949,149\u001b[0m (236.32 MB)\n",
            "\u001b[1m Non-trainable params: \u001b[0m\u001b[32m52,608\u001b[0m (205.50 KB)\n",
            "None\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "Saved Keras model to model_data/yolo.h5\n",
            "2025-05-26 00:07:07.254855: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1748218027.276418   35109 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1748218027.283118   35109 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-26 00:07:07.303848: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading model...\n",
            "2025-05-26 00:07:12.220519: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1748218032.220712   35109 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "✔ YOLO model loaded.\n",
            "Input image filename (or \"exit\" to quit): /content/drive/MyDrive/Project Folder/keras-yolo3/Car.jpg\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1748218082.322178   35149 service.cc:148] XLA service 0x7b4154003220 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1748218082.322219   35149 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2025-05-26 00:08:02.405255: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "I0000 00:00:1748218082.913074   35149 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
            "I0000 00:00:1748218086.521446   35149 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
            "Found 20 objects:\n",
            "1: toaster (0.44) at [314.70914  42.71212 452.54333 265.51227]\n",
            "2: tennis racket (0.43) at [ 56.696438  39.795773 202.4957   268.6738  ]\n",
            "3: tennis racket (0.43) at [117.9612      1.1025575 285.97516   217.65758  ]\n",
            "4: tennis racket (0.43) at [ 2.6579684e+02 -2.8010911e-01  4.2905447e+02  2.1921541e+02]\n",
            "5: tennis racket (0.43) at [189.61826    -1.5094407 359.69348   220.07     ]\n",
            "6: toaster (0.43) at [ 96.57405  81.98273 235.77893 316.14755]\n",
            "7: toaster (0.42) at [320.48615 123.32238 446.45273 366.44046]\n",
            "8: tennis racket (0.42) at [ 11.334437   -1.1469803 173.82164   220.84319  ]\n",
            "9: toaster (0.42) at [279.05896  74.92957 415.78033 324.1674 ]\n",
            "10: toaster (0.41) at [168.60535  80.09578 309.38263 319.19717]\n",
            "11: toaster (0.41) at [ 61.40356 119.74041 196.78693 368.97226]\n",
            "12: tennis racket (0.41) at [ 21.322847  72.3339   163.97078  327.40472 ]\n",
            "13: toaster (0.41) at [ 97.12515 169.3365  234.65965 409.4451 ]\n",
            "14: toaster (0.41) at [133.99121  122.746956 271.00302  364.97086 ]\n",
            "15: toaster (0.40) at [240.08134 117.70396 382.2818  370.89963]\n",
            "16: toaster (0.40) at [344.30496     6.8701572 493.63898   212.88747  ]\n",
            "17: toaster (0.40) at [350.1079  80.8926 489.7139 316.2212]\n",
            "18: bird (0.39) at [113.064644 165.90523  160.21739  218.10706 ]\n",
            "19: toaster (0.39) at [ 61.444027 254.94814  196.38177  506.19983 ]\n",
            "20: bird (0.39) at [ 94.88688 165.92638 142.04877 218.19069]\n",
            "Input image filename (or \"exit\" to quit): /content/drive/MyDrive/Project Folder/keras-yolo3/Dog.webp\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Found 20 objects:\n",
            "1: tennis racket (0.33) at [258.8145  217.03728 628.0934  472.60672]\n",
            "2: toaster (0.33) at [ 673.73224  307.8362  1016.86053  565.9341 ]\n",
            "3: toaster (0.33) at [187.96    302.4444  539.30945 571.1837 ]\n",
            "4: toaster (0.33) at [424.26508 216.50838 785.03973 472.70804]\n",
            "5: toaster (0.32) at [508.57404 303.66864 862.05054 569.76605]\n",
            "6: toaster (0.32) at [348.76794 303.19012 699.89886 570.3957 ]\n",
            "7: tennis racket (0.32) at [ 94.55301 210.35196 470.20013 480.01617]\n",
            "8: tennis racket (0.32) at [581.1124  211.60846 948.1267  478.01736]\n",
            "9: tennis racket (0.32) at [ 20.479141 298.3607   384.5624   576.1475  ]\n",
            "10: bird (0.32) at [357.75284 351.5872  485.59793 410.67566]\n",
            "11: bird (0.32) at [438.14392 351.49115 565.63464 410.7792 ]\n",
            "12: bird (0.31) at [439.24164 328.33136 564.7329  387.85815]\n",
            "13: bird (0.31) at [358.11404 374.35678 485.1942  434.0241 ]\n",
            "14: bird (0.31) at [437.7056  374.56763 565.9601  433.6992 ]\n",
            "15: bird (0.31) at [439.4281  305.68756 564.3821  364.27625]\n",
            "16: bird (0.31) at [357.30524 328.76645 486.02298 387.26492]\n",
            "17: bird (0.31) at [357.76685 305.89157 485.74442 364.1691 ]\n",
            "18: bird (0.31) at [356.57928 397.2238  486.65182 457.2876 ]\n",
            "19: bird (0.31) at [277.22592 374.30466 405.4799  434.12415]\n",
            "20: tennis racket (0.31) at [334.41003 122.29489 711.6809  383.6974 ]\n",
            "Input image filename (or \"exit\" to quit): /content/drive/MyDrive/Project Folder/keras-yolo3/Lion.jpg\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Found 20 objects:\n",
            "1: tennis racket (0.35) at [148.2444  237.7584  269.32794 518.8704 ]\n",
            "2: toaster (0.35) at [234.10071 292.02203 349.5729  565.4503 ]\n",
            "3: tennis racket (0.34) at [116.63261  89.56181 244.5161  364.63452]\n",
            "4: tennis racket (0.34) at [201.44493 185.40573 327.16208 469.10663]\n",
            "5: toaster (0.34) at [177.45334 333.32465 295.752   625.6175 ]\n",
            "6: baseball bat (0.34) at [ 91.562996 186.16763  214.68182  469.36337 ]\n",
            "7: toaster (0.33) at [121.56079 327.86346 240.58638 631.58984]\n",
            "8: bird (0.33) at [166.10295 285.60095 208.01952 349.08072]\n",
            "9: toaster (0.33) at [174.34064  84.54646 298.08273 368.45767]\n",
            "10: bird (0.33) at [179.64178 361.45776 222.27939 425.2821 ]\n",
            "11: bird (0.33) at [180.31956 260.22083 221.54434 323.63782]\n",
            "12: bird (0.33) at [193.66006 336.60898 235.93207 399.42587]\n",
            "13: bird (0.33) at [179.39624 386.46924 222.49934 450.9346 ]\n",
            "14: bird (0.33) at [179.48645 311.46814 222.47063 373.95975]\n",
            "15: bird (0.33) at [207.63559 361.70276 249.66615 425.0482 ]\n",
            "16: baseball bat (0.33) at [ 35.58021 229.77052 159.65152 527.9898 ]\n",
            "17: bird (0.32) at [207.32774 386.76404 249.97466 450.5537 ]\n",
            "18: bird (0.32) at [152.14606 260.10922 194.31    323.92825]\n",
            "19: bird (0.32) at [165.41579 336.4045  208.781   399.73676]\n",
            "20: bird (0.32) at [193.63806 285.97076 235.87029 348.67163]\n",
            "Input image filename (or \"exit\" to quit): /content/drive/MyDrive/Project Folder/keras-yolo3/Zebra.jpg\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "Found 20 objects:\n",
            "1: toaster (0.37) at [ 73.474594  46.494404 121.09383  143.27943 ]\n",
            "2: toaster (0.37) at [ 97.30914   48.512135 142.72324  141.12848 ]\n",
            "3: toaster (0.37) at [ 85.397156  30.985935 132.13625  123.664986]\n",
            "4: toaster (0.37) at [ 96.4657    13.732566 143.62854  106.19465 ]\n",
            "5: tennis racket (0.37) at [ 71.439644   -2.4096029 122.90606    87.92273  ]\n",
            "6: toaster (0.36) at [ 86.295616  64.84409  131.39085  159.43587 ]\n",
            "7: toaster (0.36) at [ 51.805843 129.04735   97.31865  234.26645 ]\n",
            "8: toaster (0.36) at [ 61.991425  81.956566 109.9942   177.19705 ]\n",
            "9: toaster (0.36) at [ 28.857212 129.74318   74.63102  233.70586 ]\n",
            "10: toaster (0.36) at [ 86.34421 128.73666 131.08214 234.63068]\n",
            "11: toaster (0.36) at [ 97.668    99.3616  142.205   194.73076]\n",
            "12: toaster (0.36) at [ 38.925293  97.613495  87.26441  196.34886 ]\n",
            "13: tennis racket (0.36) at [ 15.838544  80.7393    64.611496 178.73212 ]\n",
            "14: tennis racket (0.35) at [ 49.07556   11.127238 100.068504 108.973114]\n",
            "15: toaster (0.35) at [ 37.89691  45.21131  88.30014 144.78499]\n",
            "16: tennis racket (0.35) at [ 14.292413  28.477112  65.97718  126.99264 ]\n",
            "17: bird (0.34) at [ 85.56181   98.21315  102.475815 119.48893 ]\n",
            "18: bird (0.34) at [ 85.70628   81.09485  102.34659  101.868706]\n",
            "19: bird (0.34) at [ 85.46665  106.678734 102.55723  128.37985 ]\n",
            "20: bird (0.34) at [ 79.97675   89.611984  96.68407  110.72631 ]\n",
            "Input image filename (or \"exit\" to quit): exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "import os\n",
        "\n",
        "\n",
        "os.chdir(\"/content/drive/MyDrive/Project Folder/SimpsonRecognition-master\")\n",
        "\n",
        "\n",
        "input_file = \"annotation.txt\"\n",
        "output_file = \"train_annotations.txt\"\n",
        "classes_file = \"simpsons_classes.txt\"\n",
        "\n",
        "\n",
        "base_image_dir = \"/content/drive/MyDrive/Project Folder/ObjectDetection/simpsons_dataset\"\n",
        "\n",
        "\n",
        "class_names = set()\n",
        "with open(input_file, \"r\") as f:\n",
        "    for line in f:\n",
        "        parts = line.strip().split(',')\n",
        "        if len(parts) == 6:\n",
        "            class_names.add(parts[5])\n",
        "\n",
        "class_list = sorted(class_names)\n",
        "class_to_id = {name: idx for idx, name in enumerate(class_list)}\n",
        "\n",
        "\n",
        "with open(classes_file, \"w\") as f:\n",
        "    for cls in class_list:\n",
        "        f.write(f\"{cls}\\n\")\n",
        "\n",
        "\n",
        "image_to_boxes = {}\n",
        "with open(input_file, \"r\") as f:\n",
        "    for line in f:\n",
        "        parts = line.strip().split(',')\n",
        "        if len(parts) != 6:\n",
        "            continue\n",
        "        image_path, x1, y1, x2, y2, cls_name = parts\n",
        "\n",
        "\n",
        "        if image_path.startswith('./characters/'):\n",
        "            image_path = image_path[len('./characters/'):]\n",
        "\n",
        "\n",
        "        abs_path = os.path.abspath(os.path.join(base_image_dir, image_path))\n",
        "\n",
        "\n",
        "        if not os.path.exists(abs_path):\n",
        "            print(f\"Warning: Missing image file {abs_path}\")\n",
        "            continue\n",
        "\n",
        "        class_id = class_to_id[cls_name]\n",
        "        box = f\"{x1},{y1},{x2},{y2},{class_id}\"\n",
        "        if abs_path not in image_to_boxes:\n",
        "            image_to_boxes[abs_path] = []\n",
        "        image_to_boxes[abs_path].append(box)\n",
        "\n",
        "\n",
        "with open(output_file, \"w\") as f:\n",
        "    for img_path, boxes in image_to_boxes.items():\n",
        "        f.write(f\"{img_path} {' '.join(boxes)}\\n\")\n",
        "\n",
        "print(f\"✔ Saved {len(class_list)} classes to: {os.path.abspath(classes_file)}\")\n",
        "print(f\"✔ Annotations saved to: {os.path.abspath(output_file)}\")\n",
        "print(f\"✔ Total annotated images: {len(image_to_boxes)}\")\n",
        "\n",
        "%cd \"/content/drive/MyDrive/Project Folder/keras-yolo3\"\n",
        "!python train.py\n"
      ],
      "metadata": {
        "id": "cuwcJGWyemvE",
        "outputId": "fe56defa-9dd0-4f8e-b0a9-c69768324203",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "✔ Saved 18 classes to: /content/drive/MyDrive/Project Folder/SimpsonRecognition-master/simpsons_classes.txt\n",
            "✔ Annotations saved to: /content/drive/MyDrive/Project Folder/SimpsonRecognition-master/train_annotations.txt\n",
            "✔ Total annotated images: 7889\n",
            "/content/drive/MyDrive/Project Folder/keras-yolo3\n",
            "2025-05-30 00:04:36.361697: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1748563476.381751    1770 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1748563476.387613    1770 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-30 00:04:36.406591: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "  warnings.warn(\n",
            "2025-05-30 00:04:45.453275: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1748563485.455093    1770 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "Create YOLO model with 9 anchors and 18 classes.\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/legacy/saving/legacy_h5_format.py:513: UserWarning: Skipping loading weights for layer #217 (named conv2d_64)due to mismatch in shape for weight conv2d_64/kernel. Weight expects shape (1, 1, 256, 69). Received saved weight with shape (1, 1, 512, 256)\n",
            "  _set_weights(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/legacy/saving/legacy_h5_format.py:513: UserWarning: Skipping loading weights for layer #234 (named conv2d_71)due to mismatch in shape for weight conv2d_71/kernel. Weight expects shape (1, 1, 128, 69). Received saved weight with shape (3, 3, 128, 256)\n",
            "  _set_weights(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/legacy/saving/legacy_h5_format.py:513: UserWarning: Skipping loading weights for layer #240 (named conv2d_57)due to mismatch in shape for weight conv2d_57/kernel. Weight expects shape (1, 1, 512, 69). Received saved weight with shape (3, 3, 512, 1024)\n",
            "  _set_weights(\n",
            "Load weights model_data/yolo.h5.\n",
            "Freeze the first 102 layers of total 105 layers.\n",
            "Training on 7101 samples, validating on 788 samples, batch size 4\n",
            "Epoch 1/10\n",
            "I0000 00:00:1748563512.505578    1770 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
            "\u001b[1m 633/1775\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:07:02\u001b[0m 4s/step - loss: 22668.4883"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.Backbone Network: Darknet-53\n",
        "\n",
        "YOLOv3 utilizes Darknet-53, a 53-layer convolutional network with residual connections, for feature extraction.\n",
        "\n",
        "Code Reference:\n",
        "The backbone is implemented in the yolo_body function within the yolo3.model module, which is invoked here:\n",
        "\n",
        "##model_body = yolo_body(image_input, num_anchors//3, num_classes)\n",
        "\n",
        "This constructs the core YOLOv3 model architecture.\n",
        "\n",
        "2.Multi-Scale Predictions\n",
        "\n",
        "YOLOv3 predicts bounding boxes at three different scales to detect objects of varying sizes.\n",
        "\n",
        "Code Reference:\n",
        "The model outputs predictions at three scales, corresponding to different feature map sizes. The loss function combines these outputs:\n",
        "\n",
        "#model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n",
        "                     arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.5})([*model_body.output, *y_true])\n",
        "\n",
        "Here, y_true contains ground truth tensors for each scale, and model_body.output provides the corresponding predictions.\n",
        "\n",
        "3.Anchor Boxes\n",
        "\n",
        "YOLOv3 uses predefined anchor boxes to predict bounding boxes\n",
        "Code Reference:\n",
        "Anchor boxes are loaded and reshaped as follows:\n",
        "\n",
        "#def get_anchors(anchors_path):\n",
        "    with open(anchors_path) as f:\n",
        "        anchors = f.readline()\n",
        "    return np.array([float(x) for x in anchors.split(',')]).reshape(-1, 2)\n",
        "\n",
        "These anchors are then utilized in the loss function to guide bounding box predictions.\n",
        "\n",
        "4.Loss Function: YOLO Loss\n",
        "\n",
        "The loss function in YOLOv3 comprises multiple components, including localization, confidence, and classification losses.\n",
        "\n",
        "Code Reference:\n",
        "The custom loss function is applied using a Lambda layer:\n",
        "\n",
        "#model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n",
        "                     arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.5})([*model_body.output, *y_true])\n",
        "This setup allows the model to compute the combined loss during training.\n",
        "\n",
        "5.Training Strategy: Layer Freezing and Fine-Tuning\n",
        "\n",
        "To stabilize training, initial layers are frozen, and later all layers are unfrozen for fine-tuning.\n",
        "\n",
        "Code Reference:\n",
        "Layers are frozen based on the freeze_body parameter:\n",
        "\n",
        "#if freeze_body in [1, 2]:\n",
        "    num = (185, len(model_body.layers)-3)[freeze_body-1]\n",
        "    for i in range(num):\n",
        "        model_body.layers[i].trainable = False\n",
        "    print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
        "Later, all layers are unfrozen for further training:\n",
        "\n",
        "#for layer in model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "6.Data Augmentation\n",
        "\n",
        "Data augmentation techniques are applied to enhance model generalization.\n",
        "\n",
        "Code Reference:\n",
        "The get_random_data function applies random transformations to the input images:\n",
        "\n",
        "#image, box = get_random_data(annotation_lines[i], input_shape, random=True)\n",
        "\n",
        "7.raining Pipeline: Data Generators and Model Fitting\n",
        "\n",
        "The training process utilizes data generators and the Keras fit method.\n",
        "\n",
        "Code Reference:\n",
        "Data generators are defined as:\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_generator(\n",
        "    lambda: data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
        "    output_signature=get_output_signature(input_shape, anchors, num_classes, batch_size)\n",
        ")\n",
        "\n",
        "The model is trained using:\n",
        "\n",
        "model.fit(\n",
        "    train_dataset,\n",
        "    steps_per_epoch=max(1, num_train // batch_size),\n",
        "    validation_data=val_dataset,\n",
        "    validation_steps=max(1, num_val // batch_size),\n",
        "    epochs=50,\n",
        "    callbacks=[logging, checkpoint]\n",
        ")\n",
        "\n",
        "8.Optimization: Learning Rate Scheduling and Early Stopping\n",
        "\n",
        "To improve training efficiency, learning rate reduction and early stopping are implemented.\n",
        "\n",
        "Code Reference:\n",
        "Callbacks are set up as follows:\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)\n",
        "\n",
        "These callbacks adjust the learning rate when the validation loss plateaus and stop training when no improvement is observed.\n"
      ],
      "metadata": {
        "id": "W_DLKyYEk3VK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "207IY57HfZZL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}