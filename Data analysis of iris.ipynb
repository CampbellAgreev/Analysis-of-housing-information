{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Loading the iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Creating a DataFrame for the explanatory variables\n",
    "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "\n",
    "#the DataFrame\n",
    "print(X)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Loading the iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Creating a DataFrame for the explanatory variables\n",
    "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "\n",
    "# target variable (objective variable) in y\n",
    "y = pd.Series(iris.target, name='species')\n",
    "\n",
    "print(X)\n",
    "print(y)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Loading the iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Creating a DataFrame for the explanatory variables\n",
    "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "\n",
    "#target variable (objective variable) in y\n",
    "y = pd.Series(iris.target, name='species')\n",
    "\n",
    "# X and y into a single DataFrame\n",
    "df = pd.concat([X, y], axis=1)\n",
    "\n",
    "print(df)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Loading the iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Creating a DataFrame for the explanatory variables (X)\n",
    "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "\n",
    "# target variable (objective variable) in y\n",
    "y = pd.Series(iris.target, name='species')\n",
    "\n",
    "#X and y into a single DataFrame using pd.concat\n",
    "df = pd.concat([X, y], axis=1)\n",
    "\n",
    "#\n",
    "print(\"4th sample (index 3):\")\n",
    "print(df.iloc[3])\n",
    "\n",
    "#total number of samples for each label\n",
    "print(\"\\nTotal number of samples for each label:\")\n",
    "print(df['species'].value_counts())\n",
    "\n",
    "# \n",
    "print(\"\\nMissing values in the DataFrame:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# the mean, standard deviation, and quartiles of the feature values\n",
    "print(\"\\nMean, Standard Deviation, and Quartiles of the feature values:\")\n",
    "print(df.describe())\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Loading the iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Creating a DataFrame for the explanatory variables (X)\n",
    "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "\n",
    "#target variable (objective variable) in y\n",
    "y = pd.Series(iris.target, name='species')\n",
    "\n",
    "#X and y into a single DataFrame using pd.concat\n",
    "df = pd.concat([X, y], axis=1)\n",
    "\n",
    "#sepal_width column in two different ways\n",
    "sepal_width_loc = df.loc[:, 'sepal width (cm)']  # Using .loc[]\n",
    "sepal_width_iloc = df.iloc[:, 1]  # Using .iloc[]\n",
    "\n",
    "#the 50th to 99th data (rows 50 to 99)\n",
    "rows_50_to_99 = df.iloc[50:100]\n",
    "\n",
    "#50th to 99th data of the petal_length column\n",
    "petal_length_50_to_99 = df.iloc[50:100, 2]\n",
    "\n",
    "#data with a petal_width value of 0.2\n",
    "petal_width_02 = df.loc[df['petal width (cm)'] == 0.2]\n",
    "\n",
    "#results\n",
    "print(\"Sepal Width (using .loc):\\n\", sepal_width_loc.head())\n",
    "print(\"\\nSepal Width (using .iloc):\\n\", sepal_width_iloc.head())\n",
    "print(\"\\nRows 50 to 99:\\n\", rows_50_to_99.head())\n",
    "print(\"\\nPetal Length (50th to 99th data):\\n\", petal_length_50_to_99.head())\n",
    "print(\"\\nPetal Width = 0.2 data:\\n\", petal_width_02.head())\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Loading the iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Creating a DataFrame for the explanatory variables (X)\n",
    "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "\n",
    "#target variable (objective variable) in y\n",
    "y = pd.Series(iris.target, name='species')\n",
    "\n",
    "#X and y into a single DataFrame using pd.concat\n",
    "df = pd.concat([X, y], axis=1)\n",
    "\n",
    "#pie chart of the number of samples per label (while showing percentages)\n",
    "species_counts = df['species'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.pie(species_counts, labels=species_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Distribution of Iris Species')\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "\n",
    "#box plot for each feature, grouped by species\n",
    "features = df.drop(columns='species').columns  # Get feature column names\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, feature in enumerate(features, 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    sns.boxplot(x='species', y=feature, data=df)\n",
    "    plt.title(f'Box Plot of {feature}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#violin plot for each feature, grouped by species\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, feature in enumerate(features, 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    sns.violinplot(x='species', y=feature, data=df)\n",
    "    plt.title(f'Violin Plot of {feature}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Loading the iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Creating a DataFrame for the explanatory variables (X)\n",
    "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "\n",
    "#target variable (objective variable) in y\n",
    "y = pd.Series(iris.target, name='species')\n",
    "\n",
    "#X and y into a single DataFrame using pd.concat\n",
    "df = pd.concat([X, y], axis=1)\n",
    "\n",
    "# Scatter plot matrix (pairplot) of all feature combinations, color-coded by species\n",
    "sns.pairplot(df, hue='species')\n",
    "plt.suptitle(\"Scatter Plot Matrix of Iris Dataset\", y=1.02)\n",
    "plt.show()\n",
    "\n",
    "#correlation coefficient matrix for the 4 features\n",
    "correlation_matrix = df.drop(columns='species').corr()\n",
    "print(\"Correlation Coefficient Matrix:\")\n",
    "print(correlation_matrix)\n",
    "\n",
    "#heatmap of the correlation matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1, fmt=\".2f\")\n",
    "plt.title(\"Correlation Coefficient Heatmap of Iris Features\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By analyzing the scatter plots, correlation matrix, and heatmap, we can see that Iris setosa is easily distinguishable from the other two species due to its smaller petal size, while Iris versicolor and Iris virginica have overlapping features, making them harder to differentiate. The strong correlation between petal length and petal width suggests that using both may be redundant, and we could rely on just one of these features along with sepal length for classification. Sepal width appears less useful due to its weaker correlation with the other features. Given the clear separation between Iris setosa and the other species, classification should be straightforward for Iris setosa, but distinguishing between Iris versicolor and Iris virginica might require more advanced techniques. These insights emphasize the importance of selecting relevant features and considering feature redundancy when building classification models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
